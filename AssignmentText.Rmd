---
title: "Assignment 5 - Alternative exercise"
author: "RF"
date: "5/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#workingdirect.
setwd("C:/Users/Reka/Desktop/x")
#libraries
pacman::p_load(tidyverse,ggplot2,lmerTest,pastecs,dplyr)
library(brms)
library(rethinking)
library(plyr)
#data
d <- read_csv("ImiInhiData.csv")
```

```{r}

###CHECKDATA### 
#2 things based on the paper: RT + incorrect answers

#1. reaction time:
ggplot(d,aes(Reaction_time))+geom_histogram() #negative? + remove outliers?
d <- d %>% subset(Reaction_time > 0.15 & Reaction_time < 2) #between 150ms and 2000ms. (mentioned in the paper) (5530 -> 5442 vl.)
ggplot(d,aes(Reaction_time))+geom_histogram()

#mean(d$Reaction_time) #better - transform?
#stat.desc(d$Reaction_time)
d$logRT <- log(d$Reaction_time)
ggplot(d,aes(logRT))+geom_histogram()
ggplot(d,aes(logRT))+geom_density()

#correct answers: - find incorrect fingers and exclude them from data?
ggplot(d,aes(Correctness))+geom_histogram()
#plotCA:
CA <- d %>% group_by(Participant, Congruity, Order_number) %>%
  dplyr::summarise(x=sum(Correctness),n=n()) # x - for the number of CAs.; n - total number
ggplot(CA,aes(x))+geom_histogram()
#RT + congruent/incong.:
ggplot(d,aes(Congruity,Reaction_time))+geom_boxplot() #longer RT for incongr.

#2. exclude participants who gave a wrong answer:
y <- unique(CA$Participant[(CA$x/CA$n)<.5])
d <- subset(d,!(Participant %in% y))

#correctanswers
CA <- d %>% group_by(Participant, Congruity,Order_number) %>% #(4676vl)
  dplyr::summarise(x=sum(Correctness),n=n())
#plot
ggplot(CA,aes(x))+geom_histogram()

d <- subset(d, Participant %in% CA$Participant[CA$n>1]) #+1outlier //4672
```

```{r, models + plots}

ggplot(d, aes(Congruity, as.numeric (Correctness)))+geom_bar(stat="identity")
ggplot(d, aes(Congruity, Reaction_time))+geom_bar(stat="identity") + facet_grid(.~Correctness)

#RT - congr:
model1 = lmer(Reaction_time ~ Congruity + (1 + Congruity|Participant), d, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(model1)

#+ time effect (meaning trials):
model2 = lmer(Reaction_time ~ Congruity  * Trial+  (1 + Trial * Congruity|Participant), d, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(model2)

#+ finger diff.
model3 = lmer(Reaction_time ~ Congruity  + Order_number +  (1 + Order_number + Congruity|Participant), d, REML=F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(model3)
#gauss.
model4 = glmer(Reaction_time ~ Congruity + Order_number +  (1 + Order_number + Congruity|Participant), d, family=gaussian(link=log), control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(model4)

#RT - congr:
model5 = lmer(Correctness ~ Congruity + (1 + Congruity|Participant), d, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(model5)

#cong/RT
ggplot(d, aes(x = Congruity,y=Reaction_time, color = Congruity)) + geom_boxplot()
ggplot(d, aes(x = Participant,y=Reaction_time, color = Congruity)) + geom_boxplot() #+participants

#anova(model1, model2, model3, model4, model5)
```

## Assignment 5 - Alternative exercise

In this alternative assignment 5, you have an experimentally collected dataset and a hypothesis to test. You have to produce i) a R markdown script detailing the data preprocessing (looking at the data, making sure that there are no weird values, dealing with weird values if there are, etc.) and the data analysis process (model building including prior testing, model fitting, quality check) and ii) a text document with the answer to the questions in the document below. N.B. the analysis has to employ a Bayesian framework.

### Background

A key question to understand human cognition is how much is our cognition permeated by social information at both implicit and explicit levels. An interesting approach to the implicit use of information is the “imitation inhibition task” (read the following for details on the set-up: Simonsen et al (2018) Enhanced Automatic Action Imitation and Intact Imitation-Inhibition in Schizophrenia, Schizophrenia Bulletin, https://doi.org/10.1093/schbul/sby006)

We therefore tried to replicate the basic experiment on CogSci students: participants have to move their index finger when “1” appears on the screen, and their middle finger when “2” appears on the screen. Meanwhile, on the background of the screen two fingers might either move congruently (the same finger as the instructions dictate moves) or incongruently (the opposite finger moves).
The hypothesis is that the background “social” information will influence the performance of the participants, even when explicitly irrelevant to solve the task, thus supporting the idea that humans continuously and implicitly use social information.

The dataset (here: https://www.dropbox.com/s/1ehgvlcvtsf5q46/ImiInhiData.csv?dl=0 ) contains 8 variables:

1.	Trial: a number from 0 to 119, indicating the trial
2.	Congruity: indicating condition (background fingers moving congruently or not
3.	Reaction_time: indicating reaction time in milliseconds
4.	Response: indicating which finger was raised. “lcmd” indicates the index, “lalt” indicates the middle finger
5.	Correctness: indicating whether the response was the correct one (following the instructions) or not
6.	Order_number: indicating what the instructions said
7.	Finger_Screen: indicating which finger moved on the screen
8.	ID: indicating participant ID

### Assignment

Answer the following questions:

1.	Did you find any issue in the data? Which? How did you deal with them? 
- RT, outliers, incorrect values. 

2.	How did you go about testing your hypothesis? Describe and motivate the *Bayesian* statistical procedure(s) you used:
    - model(s) (e.g. outcome likelihood, predictors, etc.) and priors
    - quality check for the models (before and after fitting the data)
    - hypothesis testing procedure (Note there is no one procedure that is better than others, so just choose what you think is more appropriate e.g. model comparison? credibility intervals? predictive error? etc.).
3.	Does the data support or weakens our hypothesis? Comment and add at least a plot to visualize your results
4.	Comment on whether all participants show the same patterns (aka discuss the random effects). Use a plot to visualize the effects by participant and refer to it in your answer.
5.	Discuss strength and shortcomings of the analysis.


```{r, models2}
m1 <- lmer(logRT ~ Correctness + Congruity + Correctness * Congruity + (1 + Congruity|Participant) + (1|Trial), data = d, REML = FALSE)
summary(m1)
qqnorm(residuals(m1))

m2 <- glmer(Reaction_time ~ Correctness + Congruity + Correctness * Congruity + (1 + Congruity|Participant) + (1|Trial), family = gaussian(link = "log"), data = d)
summary(m2)
qqnorm(residuals(m2))

anova(m1, m2) #for model comparison

```


```{r, prior check}
#Define the model
n <- bf(Reaction_time ~ 1)
# Ask which priors need to be defined
get_prior(n, data = d, family = poisson())
# Define the prior
prior <- c()
# Draw the consequences of priors AND likelihood (why AND?)
n_prior <- brm(n, d, prior = prior, sample_prior = "only")
# Prior Predictive Check
pp_check(n_prior)
# Repeat until you are satisfied

head(predict(n_prior))

brm <- brm(
  Reaction_time ~ 1 + (1 + Congruity|Participant), 
  prior = set_prior("uniform(0, 10)", class = "sd"),
  data = d2, 
  cores = 4
)

precis(brm)
```

```{r, bayesian}
#brm1
RT <- brm(Reaction_time ~ 1 + Congruity + (1 + Congruity|Participant), data = d, prior = NULL)
summary(RT)
plot(RT)

RTmodel<- brm(Reaction_time ~ Congruity  + (1 + Congruity|Participant), 
               data=d, 
               family=poisson(link=log),
               iter = 5000, warmup = 200, cores = 4)
summary(RTmodel)
plot(RTmodel)

#map2stan
d3 = data.frame(d$Participant, d$Congruity, d$Reaction_time) 

m6 <- rethinking::map2stan(
  alist(
    Reaction_time ~ dnorm(mu, sigma),
    mu <- a + a[Participant]*Congruity + b*Order_number,
    a ~ dnorm(0,1),
    b ~ dnorm(0,1),
    sigma ~ dnorm (0,3)
  ),control = list(adapt_delta = 0.99),warmup = 1000,iter = 5000,chains = 4,cores=4,data= d2)

precis(m6)

```
